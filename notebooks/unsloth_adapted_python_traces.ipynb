{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brttC17ujvhq"
      },
      "source": [
        "# Testing workbook. Finetuning mistral 7B on single line python traces\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "his8bqgig81n",
        "outputId": "c71a4e6d-6287-4123-8273-6ffb7bd5cdc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/home/research/.kaggle’: File exists\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "python-state-changes.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  python-state-changes.zip\n",
            "replace new_all_states.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n",
            "gsm8k-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  gsm8k-dataset.zip\n",
            "replace test.jsonl? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "! pip install -q kaggle\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "! kaggle datasets download -d frasergreenlee/python-state-changes\n",
        "! unzip \"python-state-changes.zip\"\n",
        "\n",
        "! kaggle datasets download -d manwithaflower/gsm8k-dataset\n",
        "! unzip \"gsm8k-dataset.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Converting python single line dataset to better format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hrzsd-8hhf_t"
      },
      "outputs": [],
      "source": [
        "# convert txt to json format for training\n",
        "import json\n",
        "\n",
        "\n",
        "def process_file(input_file_path, output_file_path):\n",
        "    \"\"\"some formatting issues in kaggle dataset. this fixes it.\"\"\"\n",
        "    with open(input_file_path, \"r\") as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    processed_lines = []\n",
        "    for i, line in enumerate(lines):\n",
        "        if not line.startswith(\"state:\") and i > 0:\n",
        "            processed_lines[-1] = processed_lines[-1].strip() + \" \"\n",
        "        processed_lines.append(line)\n",
        "\n",
        "    with open(output_file_path, \"w\") as file:\n",
        "        file.writelines(processed_lines)\n",
        "\n",
        "\n",
        "def convert_txt_to_json(txt_file_path, json_file_path):\n",
        "    with open(txt_file_path, \"r\") as txt_file:\n",
        "        lines = txt_file.readlines()\n",
        "        data = []\n",
        "        example = 0\n",
        "        for line in lines:\n",
        "            if (\n",
        "                line == \"\\n\"\n",
        "            ):  # first line is a newline, so skip. probably a better way to do this...\n",
        "                continue\n",
        "            # print(line.split(\"; output:\"))\n",
        "            # return\n",
        "            state_code, output = line.split(\"; output:\")\n",
        "            output = output.strip()\n",
        "            input_text = state_code.strip()\n",
        "            data.append(\n",
        "                {\"input\": input_text, \"output\": output, \"example\": example},\n",
        "            )\n",
        "            example += 1\n",
        "\n",
        "    with open(json_file_path, \"w\") as json_file:\n",
        "        json.dump(data, json_file, indent=4)\n",
        "\n",
        "\n",
        "# Specify the paths for your TXT and JSON files\n",
        "# TODO convert this to absolute filepaths if necessary\n",
        "txt_file_path = \"./new_all_states.txt\"\n",
        "txt_file_path2 = \"./new_all_states_clean.txt\"\n",
        "json_file_path = \"./python_states_singleline.json\"\n",
        "\n",
        "process_file(txt_file_path, txt_file_path2)\n",
        "convert_txt_to_json(txt_file_path2, json_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAAJX6O1kjb9"
      },
      "source": [
        "# Tokenizing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkzxljWtkmEi",
        "outputId": "32ff0a8f-2dd5-48ba-c55d-6b0a6302e373"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/research/.conda/envs/torch/lib/python3.11/site-packages (4.38.2)\n",
            "Requirement already satisfied: datasets in /home/research/.conda/envs/torch/lib/python3.11/site-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from datasets) (15.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from datasets) (2.2.1)\n",
            "Requirement already satisfied: xxhash in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
            "Requirement already satisfied: aiohttp in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from pandas->datasets) (2.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/research/.conda/envs/torch/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Lv9Q8P3NmF_b"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import torch\n",
        "major_version, minor_version = torch.cuda.get_device_capability()\n",
        "# Must install separately since Colab has torch 2.2.1, which breaks packages\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "if major_version >= 8:\n",
        "    # Use this for new GPUs like Ampere, Hopper GPUs (RTX 30xx, RTX 40xx, A100, H100, L40)\n",
        "    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
        "else:\n",
        "    # Use this for older GPUs (V100, Tesla T4, RTX 20xx)\n",
        "    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYP38DGGmGep",
        "outputId": "8cdc7186-6070-427f-b791-d5ef256cd5d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/research/.conda/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Fast Mistral patching release 2024.3\n",
            "   \\\\   /|    GPU: NVIDIA GeForce RTX 3090. Max memory: 23.483 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.2.1+cu121. CUDA = 8.6. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = TRUE. Xformers = 0.0.25. FA = True.\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 2048  # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = (\n",
        "    None  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        ")\n",
        "load_in_4bit = True  # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/mistral-7b-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
        "    \"unsloth/llama-2-7b-bnb-4bit\",\n",
        "    \"unsloth/llama-2-13b-bnb-4bit\",\n",
        "    \"unsloth/codellama-34b-bnb-4bit\",\n",
        "    \"unsloth/tinyllama-bnb-4bit\",\n",
        "    \"unsloth/gemma-7b-bnb-4bit\",  # New Google 6 trillion tokens model 2.5x faster!\n",
        "    \"unsloth/gemma-2b-bnb-4bit\",\n",
        "]  # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=\"unsloth/mistral-7b-bnb-4bit\",  # Choose ANY! eg teknium/OpenHermes-2.5-Mistral-7B\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXSJRWXJoRG-",
        "outputId": "07dd601f-f78f-4393-8cac-4289002a7153"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2024.3 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,  # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "    ],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,  # Supports any, but = 0 is optimized\n",
        "    bias=\"none\",  # Supports any, but = \"none\" is optimized\n",
        "    use_gradient_checkpointing=True,\n",
        "    random_state=3407,\n",
        "    use_rslora=False,  # We support rank stabilized LoRA\n",
        "    loftq_config=None,  # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3ba4ce6f4b214c51a7e9975dabc99e6b",
            "3db04492a53b445b86837c54d7e3e538",
            "a23ade6bae174a74b0bf5c7791c43fd5",
            "12f1cacd84ed4cb697f2518783af7c7e",
            "f2001848d8b14034a549ce96d5d0d3b9",
            "5c1d2c4e463340a4a6fcf0d1fafed2e2",
            "fee802abde054601aee6abfa38a88f70",
            "325858f661d04862bf044ccbf25cd22b",
            "aaf5062d4da2469cb32839349fec57f2",
            "a538780fd2be4f7c9f26debb7534ef18",
            "e86dee058d9d4d03bdf718598030c60f"
          ]
        },
        "id": "_42P0xt1nadY",
        "outputId": "950333bb-b42d-4633-c927-4c536a09eb90"
      },
      "outputs": [],
      "source": [
        "json_file_path = \"./python_states_singleline.json\"\n",
        "\n",
        "trace_prompt = \"\"\"<s>[INST] Below is an input which contains the state of variables and code that acts upon these variables or not. Given the state and the code give the state after the code executes for each variable. Be very careful. You should clearly outline your intermediate steps and your final answer should be a newline with exactly the variables and their values. Here is the State and Code. {}\n",
        "Now generate the final state for each variable. Generate intermediate outputs.[/INST]{}</s>\"\"\"\n",
        "\n",
        "# maybe add an actual example to the prompt that shows exactly how to outline the traces logically. Maybe not since we are doing math as the final goal.\n",
        "# worth trying though\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n",
        "\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    inputs = examples[\"input\"]\n",
        "    outputs = examples[\"output\"]\n",
        "    texts = []\n",
        "    for input, output in zip(inputs, outputs):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        # EOS token should be the </s>. If generation bugs check here first\n",
        "        text = trace_prompt.format(\n",
        "            input, output\n",
        "        )  # + EOS_TOKEN # I think that this is extra. try and see, maybe take out maybe leave in\n",
        "        texts.append(text)\n",
        "        # print(text) # had this uncommented:\n",
        "        \"\"\"<s>[INST] Below is an input which contains the state of variables and code that acts upon these variables or not.\n",
        "        Given the state and the code give the state after the code executes for each variable. Be very careful.\n",
        "        You should clearly outline your intermediate steps and your final answer should be a newline with exactly the variables and their values.\n",
        "        Here is the State and Code. state: p = 1; code: t = set([p])\n",
        "        Now generate the final state for each variable. Generate intermediate outputs.[/INST]p = 1; t = {1};</s> \"\"\"\n",
        "        # looks find I think\n",
        "    return {\n",
        "        \"text\": texts,\n",
        "    }\n",
        "\n",
        "\n",
        "pass\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"json\", data_files=json_file_path, split=\"train\")\n",
        "dataset = dataset.train_test_split(test_size=0.1)[\"test\"]  # comment out later\n",
        "dataset = dataset.map(\n",
        "    formatting_prompts_func,\n",
        "    batched=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "45ebeaf7c1584a9fb431b4ec3578af68",
            "d37d3ee0849341ba81e30633664e95ce",
            "46e4b055ad1944df979f67e6438621fd",
            "dc122e3d5c094155975a05e514749e55",
            "354078c60285458b840328a0fcd4d363",
            "d91acb1c5edd45638e057d51e67beecd",
            "8254ec7205dc48d4a0201afa3d0f62f5",
            "810fe019195e4d9583b87f28e0820a61",
            "7dfd578a14144f13b8422c94b136d688",
            "287c23361d11445a83a15cc6cfd2a789",
            "4bedc3426f3a484780d4c388c3973d31"
          ]
        },
        "id": "iWo2rcn9tOkl",
        "outputId": "f1814aa4-a31b-42eb-e346-e17abe589f9a"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "torch.cuda_set_device(1)\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dataset_num_proc=2,\n",
        "    packing=False,  # Can make training 5x faster for short sequences.\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=5,\n",
        "        # steps because epochs take forever\n",
        "        # max_steps=60,\n",
        "        num_train_epochs=5,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not torch.cuda.is_bf16_supported(),\n",
        "        bf16=torch.cuda.is_bf16_supported(),\n",
        "        logging_steps=1,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"outputs\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(torch.cuda.device_count()):\n",
        "        torch.cuda.set_device(i)\n",
        "        torch.cuda.empty_cache()  # Clear cached memory\n",
        "        # Explicitly collect garbage\n",
        "        # gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WhG-JoqLwCKl",
        "outputId": "bb858f1b-1de9-40ce-b092-0875508db348"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 896,890 | Num Epochs = 5\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 16 | Total steps = 280,275\n",
            " \"-____-\"     Number of trainable parameters = 41,943,040\n"
          ]
        }
      ],
      "source": [
        "# send model to 2nd gpu\n",
        "\n",
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSKN3GnH2YIB"
      },
      "outputs": [],
      "source": [
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model)  # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "    [\n",
        "        trace_prompt.format(\n",
        "            \"state: p = {'a': 1, 'b': 1, 'c': 1, 'd': 1}; w = 'e'; code: p[w] = 1\",  # input\n",
        "            \"\",  # output --> \"a = [1, 7, 2, 4]; c = {0: 0, 1: 1, 2: 0}; i = 0; k = 3;\"\n",
        "        )\n",
        "    ],\n",
        "    return_tensors=\"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "# outputs = model.generate(**inputs, max_new_tokens = 64, use_cache = True)\n",
        "# tokenizer.batch_decode(outputs)\n",
        "from transformers import TextStreamer\n",
        "\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finetune further on gsm8k train split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZUQfBje3gE6"
      },
      "outputs": [],
      "source": [
        "# Need to save the model\n",
        "# TODO"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12f1cacd84ed4cb697f2518783af7c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a538780fd2be4f7c9f26debb7534ef18",
            "placeholder": "​",
            "style": "IPY_MODEL_e86dee058d9d4d03bdf718598030c60f",
            "value": " 896890/896890 [00:26&lt;00:00, 28074.34 examples/s]"
          }
        },
        "287c23361d11445a83a15cc6cfd2a789": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "325858f661d04862bf044ccbf25cd22b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "354078c60285458b840328a0fcd4d363": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ba4ce6f4b214c51a7e9975dabc99e6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3db04492a53b445b86837c54d7e3e538",
              "IPY_MODEL_a23ade6bae174a74b0bf5c7791c43fd5",
              "IPY_MODEL_12f1cacd84ed4cb697f2518783af7c7e"
            ],
            "layout": "IPY_MODEL_f2001848d8b14034a549ce96d5d0d3b9"
          }
        },
        "3db04492a53b445b86837c54d7e3e538": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c1d2c4e463340a4a6fcf0d1fafed2e2",
            "placeholder": "​",
            "style": "IPY_MODEL_fee802abde054601aee6abfa38a88f70",
            "value": "Map: 100%"
          }
        },
        "45ebeaf7c1584a9fb431b4ec3578af68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d37d3ee0849341ba81e30633664e95ce",
              "IPY_MODEL_46e4b055ad1944df979f67e6438621fd",
              "IPY_MODEL_dc122e3d5c094155975a05e514749e55"
            ],
            "layout": "IPY_MODEL_354078c60285458b840328a0fcd4d363"
          }
        },
        "46e4b055ad1944df979f67e6438621fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_810fe019195e4d9583b87f28e0820a61",
            "max": 896890,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dfd578a14144f13b8422c94b136d688",
            "value": 896890
          }
        },
        "4bedc3426f3a484780d4c388c3973d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c1d2c4e463340a4a6fcf0d1fafed2e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dfd578a14144f13b8422c94b136d688": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "810fe019195e4d9583b87f28e0820a61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8254ec7205dc48d4a0201afa3d0f62f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a23ade6bae174a74b0bf5c7791c43fd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_325858f661d04862bf044ccbf25cd22b",
            "max": 896890,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aaf5062d4da2469cb32839349fec57f2",
            "value": 896890
          }
        },
        "a538780fd2be4f7c9f26debb7534ef18": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaf5062d4da2469cb32839349fec57f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d37d3ee0849341ba81e30633664e95ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d91acb1c5edd45638e057d51e67beecd",
            "placeholder": "​",
            "style": "IPY_MODEL_8254ec7205dc48d4a0201afa3d0f62f5",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "d91acb1c5edd45638e057d51e67beecd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc122e3d5c094155975a05e514749e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_287c23361d11445a83a15cc6cfd2a789",
            "placeholder": "​",
            "style": "IPY_MODEL_4bedc3426f3a484780d4c388c3973d31",
            "value": " 896890/896890 [09:13&lt;00:00, 1386.81 examples/s]"
          }
        },
        "e86dee058d9d4d03bdf718598030c60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2001848d8b14034a549ce96d5d0d3b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fee802abde054601aee6abfa38a88f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
